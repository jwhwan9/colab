{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c9507ecc75d4c3dad8ed29e4d3834dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c43c6762a1304f7b8530cce0fb7f5e26",
              "IPY_MODEL_263ac28e22eb4794b9a1c2c5a0e32ce1",
              "IPY_MODEL_4b4fef28b5a64f7387e15d8101d3f032"
            ],
            "layout": "IPY_MODEL_98e5640b427b47d486408450e5ada8f5"
          }
        },
        "c43c6762a1304f7b8530cce0fb7f5e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8755e12484545dd9f82862bf9ec5dd2",
            "placeholder": "​",
            "style": "IPY_MODEL_a0dea59aad584c04baa9927d93963f5f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "263ac28e22eb4794b9a1c2c5a0e32ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c17ef97a224507a39b4f6505061e85",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e8e5cb968e342368f1a9796d1017b59",
            "value": 5
          }
        },
        "4b4fef28b5a64f7387e15d8101d3f032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7463406996a4cefa7a7f1c8180da77a",
            "placeholder": "​",
            "style": "IPY_MODEL_7189e507138e4560ab07f81f9caa7531",
            "value": " 5/5 [00:10&lt;00:00,  1.89s/it]"
          }
        },
        "98e5640b427b47d486408450e5ada8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8755e12484545dd9f82862bf9ec5dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0dea59aad584c04baa9927d93963f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c17ef97a224507a39b4f6505061e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8e5cb968e342368f1a9796d1017b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7463406996a4cefa7a7f1c8180da77a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7189e507138e4560ab07f81f9caa7531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b970a39ea520400cae6d4de2484bae03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03c79bb931bf41449872eacfb96703b6",
              "IPY_MODEL_3f9dc842964640e099603c573d26fd50",
              "IPY_MODEL_fa966d2230a849519965a7dcadf8f0f2"
            ],
            "layout": "IPY_MODEL_51e5342d1e3c46709180b9fdf819b559"
          }
        },
        "03c79bb931bf41449872eacfb96703b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6960f8917464738b169c7eec16cc4ba",
            "placeholder": "​",
            "style": "IPY_MODEL_c90d90ac182743839ff589dd6bc99efe",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3f9dc842964640e099603c573d26fd50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6001bfbaa5864f2cad69afc93e5b338e",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_126e7c6f839d40debdb1482a5b065898",
            "value": 5
          }
        },
        "fa966d2230a849519965a7dcadf8f0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0403483809a24fc19d20c3b3216ab3d4",
            "placeholder": "​",
            "style": "IPY_MODEL_cd355fe50f7742d7885f38529e001c97",
            "value": " 5/5 [00:11&lt;00:00,  2.05s/it]"
          }
        },
        "51e5342d1e3c46709180b9fdf819b559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6960f8917464738b169c7eec16cc4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90d90ac182743839ff589dd6bc99efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6001bfbaa5864f2cad69afc93e5b338e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "126e7c6f839d40debdb1482a5b065898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0403483809a24fc19d20c3b3216ab3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd355fe50f7742d7885f38529e001c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwhwan9/colab/blob/main/Fine_tune_Llama_3_70B_on_Your_GPU_with_AQLM_Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook shows how to fine-tune Llama 3 70B quantized with AQLM to 2-bit.\n",
        "\n",
        "The notebook requires at least a 24 GB GPU.\n",
        "\n",
        "More details and comments: [Fine-tune Llama 3 70B on Your GPU with AQLM 2-bit](https://kaitchup.substack.com/p/fine-tune-llama-3-70b-on-your-gpu)\n",
        "\n",
        "We need to install:"
      ],
      "metadata": {
        "id": "lMffYXpMKl9s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AldbXQSTl4c",
        "outputId": "6533a528-46b0-4246-e429-3d4246d31e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Collecting peft\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl\n",
            "  Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.30.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flash_attn\n",
            "  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Collecting datasets (from trl)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.8.3-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from flash_attn)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from flash_attn)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->trl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
            "Collecting xxhash (from datasets->trl)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->trl)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
            "Building wheels for collected packages: flash_attn\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash_attn: filename=flash_attn-2.5.8-cp310-cp310-linux_x86_64.whl size=120853537 sha256=53979129f883680327bf5d13027cd014e2d054f4fb5b8856916686ae315e57d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/5b/2b/dea8af4e954161c49ef1941938afcd91bb93689371ed12a226\n",
            "Successfully built flash_attn\n",
            "Installing collected packages: ninja, xxhash, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, tyro, nvidia-cusolver-cu12, datasets, flash_attn, bitsandbytes, accelerate, trl, peft\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed accelerate-0.30.0 bitsandbytes-0.43.1 datasets-2.19.1 dill-0.3.8 einops-0.8.0 flash_attn-2.5.8 huggingface-hub-0.23.0 multiprocess-0.70.16 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 peft-0.10.0 shtab-1.7.1 trl-0.8.6 tyro-0.8.3 xxhash-3.4.1\n",
            "Collecting aqlm[cpu,gpu]\n",
            "  Downloading aqlm-1.1.5-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from aqlm[cpu,gpu]) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from aqlm[cpu,gpu]) (4.40.2)\n",
            "Requirement already satisfied: accelerate>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from aqlm[cpu,gpu]) (0.30.0)\n",
            "Requirement already satisfied: numba>=0.56.4 in /usr/local/lib/python3.10/dist-packages (from aqlm[cpu,gpu]) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from aqlm[cpu,gpu]) (1.11.4)\n",
            "Requirement already satisfied: triton>=2.1 in /usr/local/lib/python3.10/dist-packages (from aqlm[cpu,gpu]) (2.2.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from aqlm[cpu,gpu]) (1.11.1.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.0->aqlm[cpu,gpu]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.0->aqlm[cpu,gpu]) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.0->aqlm[cpu,gpu]) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.0->aqlm[cpu,gpu]) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.0->aqlm[cpu,gpu]) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.0->aqlm[cpu,gpu]) (0.4.3)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56.4->aqlm[cpu,gpu]) (0.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->aqlm[cpu,gpu]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->aqlm[cpu,gpu]) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->aqlm[cpu,gpu]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->aqlm[cpu,gpu]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->aqlm[cpu,gpu]) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->aqlm[cpu,gpu]) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0->aqlm[cpu,gpu]) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.38.0->aqlm[cpu,gpu]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.38.0->aqlm[cpu,gpu]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.38.0->aqlm[cpu,gpu]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.38.0->aqlm[cpu,gpu]) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0->aqlm[cpu,gpu]) (1.3.0)\n",
            "Installing collected packages: aqlm\n",
            "Successfully installed aqlm-1.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers peft trl accelerate bitsandbytes flash_attn\n",
        "!pip install aqlm[gpu,cpu]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model and its tokenizer:"
      ],
      "metadata": {
        "id": "TmQZ0EwjLs1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "\n",
        "model_id = \"ISTA-DASLab/Meta-Llama-3-70B-Instruct-AQLM-2Bit-1x16\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True, torch_dtype=torch.bfloat16, device_map=\"cuda\", low_cpu_mem_usage=True, attn_implementation=\"flash_attention_2\"\n",
        "\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "9c9507ecc75d4c3dad8ed29e4d3834dc",
            "c43c6762a1304f7b8530cce0fb7f5e26",
            "263ac28e22eb4794b9a1c2c5a0e32ce1",
            "4b4fef28b5a64f7387e15d8101d3f032",
            "98e5640b427b47d486408450e5ada8f5",
            "b8755e12484545dd9f82862bf9ec5dd2",
            "a0dea59aad584c04baa9927d93963f5f",
            "84c17ef97a224507a39b4f6505061e85",
            "4e8e5cb968e342368f1a9796d1017b59",
            "f7463406996a4cefa7a7f1c8180da77a",
            "7189e507138e4560ab07f81f9caa7531"
          ]
        },
        "id": "a70wK_MUUdz3",
        "outputId": "c447dfc6-e891-43e7-fb4c-2fb8a1800fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c9507ecc75d4c3dad8ed29e4d3834dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the model with gradient checkpointing enabled (don't forget this step otherwise you will have OOM errors)."
      ],
      "metadata": {
        "id": "pmuBETmMLx_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "7JEsD4F8VS1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, load an instruction dataset for fine-tuning:"
      ],
      "metadata": {
        "id": "H3FCXmAWL70F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"timdettmers/openassistant-guanaco\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfuCzto1ZRRy",
        "outputId": "7d5d3879-ed5e-4bfc-8558-648cccd27cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the training.\n",
        "\n",
        "Note that the notebook fine-tunes for only 100 steps. It takes 3 hours per 100 steps. Fine-tune for 2 or 3 epochs to obtain good results."
      ],
      "metadata": {
        "id": "kHMUvXSkMFQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig\n",
        "\n",
        "training_arguments = SFTConfig(\n",
        "        output_dir=\"./Llama-3-8B-aqlm-2bit-lora\",\n",
        "        evaluation_strategy=\"steps\",\n",
        "        do_eval=True,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=16,\n",
        "        per_device_eval_batch_size=1,\n",
        "        log_level=\"debug\",\n",
        "        logging_steps=25,\n",
        "        learning_rate=1e-4,\n",
        "        eval_steps=25,\n",
        "        save_steps=50,\n",
        "        bf16=True,\n",
        "        save_strategy='steps',\n",
        "        max_steps=200,\n",
        "        warmup_steps=25,\n",
        "        lr_scheduler_type=\"linear\",\n",
        ")\n",
        "\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "        lora_alpha=8,\n",
        "        lora_dropout=0.05,\n",
        "        r=8,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules= [\"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        train_dataset=dataset['train'],\n",
        "        eval_dataset=dataset['test'],\n",
        "        peft_config=peft_config,\n",
        "        dataset_text_field=\"text\",\n",
        "        max_seq_length=256,\n",
        "        tokenizer=tokenizer,\n",
        "        args=training_arguments,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "veJZT5xSU-jF",
        "outputId": "d2456b51-21db-4de7-dcb4-21a18f00bfd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "Using auto half precision backend\n",
            "Currently training with a batch size of: 1\n",
            "***** Running training *****\n",
            "  Num examples = 9,846\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 200\n",
            "  Number of trainable parameters = 70,778,880\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='76' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 76/200 57:40 < 1:36:38, 0.02 it/s, Epoch 0.12/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.861800</td>\n",
              "      <td>1.622912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.479300</td>\n",
              "      <td>1.489627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='518' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/518 01:13 < 05:08, 1.35 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 518\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 518\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-50\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--ISTA-DASLab--Meta-Llama-3-70B-Instruct-AQLM-2Bit-1x16/snapshots/f4ca0b50cf3c348d92b60cf98216ae6294f180cf/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"/slot/sandbox/j/_tmp/data3p0913nd\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 8192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 28672,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_layers\": 80,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"in_group_size\": 8,\n",
            "    \"linear_weights_not_to_quantize\": [\n",
            "      \"model.layers.0.input_layernorm.weight\",\n",
            "      \"model.layers.0.post_attention_layernorm.weight\",\n",
            "      \"model.layers.1.input_layernorm.weight\",\n",
            "      \"model.layers.1.post_attention_layernorm.weight\",\n",
            "      \"model.layers.2.input_layernorm.weight\",\n",
            "      \"model.layers.2.post_attention_layernorm.weight\",\n",
            "      \"model.layers.3.input_layernorm.weight\",\n",
            "      \"model.layers.3.post_attention_layernorm.weight\",\n",
            "      \"model.layers.4.input_layernorm.weight\",\n",
            "      \"model.layers.4.post_attention_layernorm.weight\",\n",
            "      \"model.layers.5.input_layernorm.weight\",\n",
            "      \"model.layers.5.post_attention_layernorm.weight\",\n",
            "      \"model.layers.6.input_layernorm.weight\",\n",
            "      \"model.layers.6.post_attention_layernorm.weight\",\n",
            "      \"model.layers.7.input_layernorm.weight\",\n",
            "      \"model.layers.7.post_attention_layernorm.weight\",\n",
            "      \"model.layers.8.input_layernorm.weight\",\n",
            "      \"model.layers.8.post_attention_layernorm.weight\",\n",
            "      \"model.layers.9.input_layernorm.weight\",\n",
            "      \"model.layers.9.post_attention_layernorm.weight\",\n",
            "      \"model.layers.10.input_layernorm.weight\",\n",
            "      \"model.layers.10.post_attention_layernorm.weight\",\n",
            "      \"model.layers.11.input_layernorm.weight\",\n",
            "      \"model.layers.11.post_attention_layernorm.weight\",\n",
            "      \"model.layers.12.input_layernorm.weight\",\n",
            "      \"model.layers.12.post_attention_layernorm.weight\",\n",
            "      \"model.layers.13.input_layernorm.weight\",\n",
            "      \"model.layers.13.post_attention_layernorm.weight\",\n",
            "      \"model.layers.14.input_layernorm.weight\",\n",
            "      \"model.layers.14.post_attention_layernorm.weight\",\n",
            "      \"model.layers.15.input_layernorm.weight\",\n",
            "      \"model.layers.15.post_attention_layernorm.weight\",\n",
            "      \"model.layers.16.input_layernorm.weight\",\n",
            "      \"model.layers.16.post_attention_layernorm.weight\",\n",
            "      \"model.layers.17.input_layernorm.weight\",\n",
            "      \"model.layers.17.post_attention_layernorm.weight\",\n",
            "      \"model.layers.18.input_layernorm.weight\",\n",
            "      \"model.layers.18.post_attention_layernorm.weight\",\n",
            "      \"model.layers.19.input_layernorm.weight\",\n",
            "      \"model.layers.19.post_attention_layernorm.weight\",\n",
            "      \"model.layers.20.input_layernorm.weight\",\n",
            "      \"model.layers.20.post_attention_layernorm.weight\",\n",
            "      \"model.layers.21.input_layernorm.weight\",\n",
            "      \"model.layers.21.post_attention_layernorm.weight\",\n",
            "      \"model.layers.22.input_layernorm.weight\",\n",
            "      \"model.layers.22.post_attention_layernorm.weight\",\n",
            "      \"model.layers.23.input_layernorm.weight\",\n",
            "      \"model.layers.23.post_attention_layernorm.weight\",\n",
            "      \"model.layers.24.input_layernorm.weight\",\n",
            "      \"model.layers.24.post_attention_layernorm.weight\",\n",
            "      \"model.layers.25.input_layernorm.weight\",\n",
            "      \"model.layers.25.post_attention_layernorm.weight\",\n",
            "      \"model.layers.26.input_layernorm.weight\",\n",
            "      \"model.layers.26.post_attention_layernorm.weight\",\n",
            "      \"model.layers.27.input_layernorm.weight\",\n",
            "      \"model.layers.27.post_attention_layernorm.weight\",\n",
            "      \"model.layers.28.input_layernorm.weight\",\n",
            "      \"model.layers.28.post_attention_layernorm.weight\",\n",
            "      \"model.layers.29.input_layernorm.weight\",\n",
            "      \"model.layers.29.post_attention_layernorm.weight\",\n",
            "      \"model.layers.30.input_layernorm.weight\",\n",
            "      \"model.layers.30.post_attention_layernorm.weight\",\n",
            "      \"model.layers.31.input_layernorm.weight\",\n",
            "      \"model.layers.31.post_attention_layernorm.weight\",\n",
            "      \"model.layers.32.input_layernorm.weight\",\n",
            "      \"model.layers.32.post_attention_layernorm.weight\",\n",
            "      \"model.layers.33.input_layernorm.weight\",\n",
            "      \"model.layers.33.post_attention_layernorm.weight\",\n",
            "      \"model.layers.34.input_layernorm.weight\",\n",
            "      \"model.layers.34.post_attention_layernorm.weight\",\n",
            "      \"model.layers.35.input_layernorm.weight\",\n",
            "      \"model.layers.35.post_attention_layernorm.weight\",\n",
            "      \"model.layers.36.input_layernorm.weight\",\n",
            "      \"model.layers.36.post_attention_layernorm.weight\",\n",
            "      \"model.layers.37.input_layernorm.weight\",\n",
            "      \"model.layers.37.post_attention_layernorm.weight\",\n",
            "      \"model.layers.38.input_layernorm.weight\",\n",
            "      \"model.layers.38.post_attention_layernorm.weight\",\n",
            "      \"model.layers.39.input_layernorm.weight\",\n",
            "      \"model.layers.39.post_attention_layernorm.weight\",\n",
            "      \"model.layers.40.input_layernorm.weight\",\n",
            "      \"model.layers.40.post_attention_layernorm.weight\",\n",
            "      \"model.layers.41.input_layernorm.weight\",\n",
            "      \"model.layers.41.post_attention_layernorm.weight\",\n",
            "      \"model.layers.42.input_layernorm.weight\",\n",
            "      \"model.layers.42.post_attention_layernorm.weight\",\n",
            "      \"model.layers.43.input_layernorm.weight\",\n",
            "      \"model.layers.43.post_attention_layernorm.weight\",\n",
            "      \"model.layers.44.input_layernorm.weight\",\n",
            "      \"model.layers.44.post_attention_layernorm.weight\",\n",
            "      \"model.layers.45.input_layernorm.weight\",\n",
            "      \"model.layers.45.post_attention_layernorm.weight\",\n",
            "      \"model.layers.46.input_layernorm.weight\",\n",
            "      \"model.layers.46.post_attention_layernorm.weight\",\n",
            "      \"model.layers.47.input_layernorm.weight\",\n",
            "      \"model.layers.47.post_attention_layernorm.weight\",\n",
            "      \"model.layers.48.input_layernorm.weight\",\n",
            "      \"model.layers.48.post_attention_layernorm.weight\",\n",
            "      \"model.layers.49.input_layernorm.weight\",\n",
            "      \"model.layers.49.post_attention_layernorm.weight\",\n",
            "      \"model.layers.50.input_layernorm.weight\",\n",
            "      \"model.layers.50.post_attention_layernorm.weight\",\n",
            "      \"model.layers.51.input_layernorm.weight\",\n",
            "      \"model.layers.51.post_attention_layernorm.weight\",\n",
            "      \"model.layers.52.input_layernorm.weight\",\n",
            "      \"model.layers.52.post_attention_layernorm.weight\",\n",
            "      \"model.layers.53.input_layernorm.weight\",\n",
            "      \"model.layers.53.post_attention_layernorm.weight\",\n",
            "      \"model.layers.54.input_layernorm.weight\",\n",
            "      \"model.layers.54.post_attention_layernorm.weight\",\n",
            "      \"model.layers.55.input_layernorm.weight\",\n",
            "      \"model.layers.55.post_attention_layernorm.weight\",\n",
            "      \"model.layers.56.input_layernorm.weight\",\n",
            "      \"model.layers.56.post_attention_layernorm.weight\",\n",
            "      \"model.layers.57.input_layernorm.weight\",\n",
            "      \"model.layers.57.post_attention_layernorm.weight\",\n",
            "      \"model.layers.58.input_layernorm.weight\",\n",
            "      \"model.layers.58.post_attention_layernorm.weight\",\n",
            "      \"model.layers.59.input_layernorm.weight\",\n",
            "      \"model.layers.59.post_attention_layernorm.weight\",\n",
            "      \"model.layers.60.input_layernorm.weight\",\n",
            "      \"model.layers.60.post_attention_layernorm.weight\",\n",
            "      \"model.layers.61.input_layernorm.weight\",\n",
            "      \"model.layers.61.post_attention_layernorm.weight\",\n",
            "      \"model.layers.62.input_layernorm.weight\",\n",
            "      \"model.layers.62.post_attention_layernorm.weight\",\n",
            "      \"model.layers.63.input_layernorm.weight\",\n",
            "      \"model.layers.63.post_attention_layernorm.weight\",\n",
            "      \"model.layers.64.input_layernorm.weight\",\n",
            "      \"model.layers.64.post_attention_layernorm.weight\",\n",
            "      \"model.layers.65.input_layernorm.weight\",\n",
            "      \"model.layers.65.post_attention_layernorm.weight\",\n",
            "      \"model.layers.66.input_layernorm.weight\",\n",
            "      \"model.layers.66.post_attention_layernorm.weight\",\n",
            "      \"model.layers.67.input_layernorm.weight\",\n",
            "      \"model.layers.67.post_attention_layernorm.weight\",\n",
            "      \"model.layers.68.input_layernorm.weight\",\n",
            "      \"model.layers.68.post_attention_layernorm.weight\",\n",
            "      \"model.layers.69.input_layernorm.weight\",\n",
            "      \"model.layers.69.post_attention_layernorm.weight\",\n",
            "      \"model.layers.70.input_layernorm.weight\",\n",
            "      \"model.layers.70.post_attention_layernorm.weight\",\n",
            "      \"model.layers.71.input_layernorm.weight\",\n",
            "      \"model.layers.71.post_attention_layernorm.weight\",\n",
            "      \"model.layers.72.input_layernorm.weight\",\n",
            "      \"model.layers.72.post_attention_layernorm.weight\",\n",
            "      \"model.layers.73.input_layernorm.weight\",\n",
            "      \"model.layers.73.post_attention_layernorm.weight\",\n",
            "      \"model.layers.74.input_layernorm.weight\",\n",
            "      \"model.layers.74.post_attention_layernorm.weight\",\n",
            "      \"model.layers.75.input_layernorm.weight\",\n",
            "      \"model.layers.75.post_attention_layernorm.weight\",\n",
            "      \"model.layers.76.input_layernorm.weight\",\n",
            "      \"model.layers.76.post_attention_layernorm.weight\",\n",
            "      \"model.layers.77.input_layernorm.weight\",\n",
            "      \"model.layers.77.post_attention_layernorm.weight\",\n",
            "      \"model.layers.78.input_layernorm.weight\",\n",
            "      \"model.layers.78.post_attention_layernorm.weight\",\n",
            "      \"model.layers.79.input_layernorm.weight\",\n",
            "      \"model.layers.79.post_attention_layernorm.weight\",\n",
            "      \"model.embed_tokens.weight\",\n",
            "      \"model.norm.weight\",\n",
            "      \"lm_head.weight\"\n",
            "    ],\n",
            "    \"nbits_per_codebook\": 16,\n",
            "    \"num_codebooks\": 1,\n",
            "    \"out_group_size\": 1,\n",
            "    \"quant_method\": \"aqlm\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-50/tokenizer_config.json\n",
            "Special tokens file saved in ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-50/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 518\n",
            "  Batch size = 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 2:51:52, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.861800</td>\n",
              "      <td>1.622912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.479300</td>\n",
              "      <td>1.489627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.453500</td>\n",
              "      <td>1.467766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.423700</td>\n",
              "      <td>1.454094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.416100</td>\n",
              "      <td>1.446623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.424100</td>\n",
              "      <td>1.440638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.416000</td>\n",
              "      <td>1.438630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.421600</td>\n",
              "      <td>1.437365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 518\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-100\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--ISTA-DASLab--Meta-Llama-3-70B-Instruct-AQLM-2Bit-1x16/snapshots/f4ca0b50cf3c348d92b60cf98216ae6294f180cf/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"/slot/sandbox/j/_tmp/data3p0913nd\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 8192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 28672,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_layers\": 80,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"in_group_size\": 8,\n",
            "    \"linear_weights_not_to_quantize\": [\n",
            "      \"model.layers.0.input_layernorm.weight\",\n",
            "      \"model.layers.0.post_attention_layernorm.weight\",\n",
            "      \"model.layers.1.input_layernorm.weight\",\n",
            "      \"model.layers.1.post_attention_layernorm.weight\",\n",
            "      \"model.layers.2.input_layernorm.weight\",\n",
            "      \"model.layers.2.post_attention_layernorm.weight\",\n",
            "      \"model.layers.3.input_layernorm.weight\",\n",
            "      \"model.layers.3.post_attention_layernorm.weight\",\n",
            "      \"model.layers.4.input_layernorm.weight\",\n",
            "      \"model.layers.4.post_attention_layernorm.weight\",\n",
            "      \"model.layers.5.input_layernorm.weight\",\n",
            "      \"model.layers.5.post_attention_layernorm.weight\",\n",
            "      \"model.layers.6.input_layernorm.weight\",\n",
            "      \"model.layers.6.post_attention_layernorm.weight\",\n",
            "      \"model.layers.7.input_layernorm.weight\",\n",
            "      \"model.layers.7.post_attention_layernorm.weight\",\n",
            "      \"model.layers.8.input_layernorm.weight\",\n",
            "      \"model.layers.8.post_attention_layernorm.weight\",\n",
            "      \"model.layers.9.input_layernorm.weight\",\n",
            "      \"model.layers.9.post_attention_layernorm.weight\",\n",
            "      \"model.layers.10.input_layernorm.weight\",\n",
            "      \"model.layers.10.post_attention_layernorm.weight\",\n",
            "      \"model.layers.11.input_layernorm.weight\",\n",
            "      \"model.layers.11.post_attention_layernorm.weight\",\n",
            "      \"model.layers.12.input_layernorm.weight\",\n",
            "      \"model.layers.12.post_attention_layernorm.weight\",\n",
            "      \"model.layers.13.input_layernorm.weight\",\n",
            "      \"model.layers.13.post_attention_layernorm.weight\",\n",
            "      \"model.layers.14.input_layernorm.weight\",\n",
            "      \"model.layers.14.post_attention_layernorm.weight\",\n",
            "      \"model.layers.15.input_layernorm.weight\",\n",
            "      \"model.layers.15.post_attention_layernorm.weight\",\n",
            "      \"model.layers.16.input_layernorm.weight\",\n",
            "      \"model.layers.16.post_attention_layernorm.weight\",\n",
            "      \"model.layers.17.input_layernorm.weight\",\n",
            "      \"model.layers.17.post_attention_layernorm.weight\",\n",
            "      \"model.layers.18.input_layernorm.weight\",\n",
            "      \"model.layers.18.post_attention_layernorm.weight\",\n",
            "      \"model.layers.19.input_layernorm.weight\",\n",
            "      \"model.layers.19.post_attention_layernorm.weight\",\n",
            "      \"model.layers.20.input_layernorm.weight\",\n",
            "      \"model.layers.20.post_attention_layernorm.weight\",\n",
            "      \"model.layers.21.input_layernorm.weight\",\n",
            "      \"model.layers.21.post_attention_layernorm.weight\",\n",
            "      \"model.layers.22.input_layernorm.weight\",\n",
            "      \"model.layers.22.post_attention_layernorm.weight\",\n",
            "      \"model.layers.23.input_layernorm.weight\",\n",
            "      \"model.layers.23.post_attention_layernorm.weight\",\n",
            "      \"model.layers.24.input_layernorm.weight\",\n",
            "      \"model.layers.24.post_attention_layernorm.weight\",\n",
            "      \"model.layers.25.input_layernorm.weight\",\n",
            "      \"model.layers.25.post_attention_layernorm.weight\",\n",
            "      \"model.layers.26.input_layernorm.weight\",\n",
            "      \"model.layers.26.post_attention_layernorm.weight\",\n",
            "      \"model.layers.27.input_layernorm.weight\",\n",
            "      \"model.layers.27.post_attention_layernorm.weight\",\n",
            "      \"model.layers.28.input_layernorm.weight\",\n",
            "      \"model.layers.28.post_attention_layernorm.weight\",\n",
            "      \"model.layers.29.input_layernorm.weight\",\n",
            "      \"model.layers.29.post_attention_layernorm.weight\",\n",
            "      \"model.layers.30.input_layernorm.weight\",\n",
            "      \"model.layers.30.post_attention_layernorm.weight\",\n",
            "      \"model.layers.31.input_layernorm.weight\",\n",
            "      \"model.layers.31.post_attention_layernorm.weight\",\n",
            "      \"model.layers.32.input_layernorm.weight\",\n",
            "      \"model.layers.32.post_attention_layernorm.weight\",\n",
            "      \"model.layers.33.input_layernorm.weight\",\n",
            "      \"model.layers.33.post_attention_layernorm.weight\",\n",
            "      \"model.layers.34.input_layernorm.weight\",\n",
            "      \"model.layers.34.post_attention_layernorm.weight\",\n",
            "      \"model.layers.35.input_layernorm.weight\",\n",
            "      \"model.layers.35.post_attention_layernorm.weight\",\n",
            "      \"model.layers.36.input_layernorm.weight\",\n",
            "      \"model.layers.36.post_attention_layernorm.weight\",\n",
            "      \"model.layers.37.input_layernorm.weight\",\n",
            "      \"model.layers.37.post_attention_layernorm.weight\",\n",
            "      \"model.layers.38.input_layernorm.weight\",\n",
            "      \"model.layers.38.post_attention_layernorm.weight\",\n",
            "      \"model.layers.39.input_layernorm.weight\",\n",
            "      \"model.layers.39.post_attention_layernorm.weight\",\n",
            "      \"model.layers.40.input_layernorm.weight\",\n",
            "      \"model.layers.40.post_attention_layernorm.weight\",\n",
            "      \"model.layers.41.input_layernorm.weight\",\n",
            "      \"model.layers.41.post_attention_layernorm.weight\",\n",
            "      \"model.layers.42.input_layernorm.weight\",\n",
            "      \"model.layers.42.post_attention_layernorm.weight\",\n",
            "      \"model.layers.43.input_layernorm.weight\",\n",
            "      \"model.layers.43.post_attention_layernorm.weight\",\n",
            "      \"model.layers.44.input_layernorm.weight\",\n",
            "      \"model.layers.44.post_attention_layernorm.weight\",\n",
            "      \"model.layers.45.input_layernorm.weight\",\n",
            "      \"model.layers.45.post_attention_layernorm.weight\",\n",
            "      \"model.layers.46.input_layernorm.weight\",\n",
            "      \"model.layers.46.post_attention_layernorm.weight\",\n",
            "      \"model.layers.47.input_layernorm.weight\",\n",
            "      \"model.layers.47.post_attention_layernorm.weight\",\n",
            "      \"model.layers.48.input_layernorm.weight\",\n",
            "      \"model.layers.48.post_attention_layernorm.weight\",\n",
            "      \"model.layers.49.input_layernorm.weight\",\n",
            "      \"model.layers.49.post_attention_layernorm.weight\",\n",
            "      \"model.layers.50.input_layernorm.weight\",\n",
            "      \"model.layers.50.post_attention_layernorm.weight\",\n",
            "      \"model.layers.51.input_layernorm.weight\",\n",
            "      \"model.layers.51.post_attention_layernorm.weight\",\n",
            "      \"model.layers.52.input_layernorm.weight\",\n",
            "      \"model.layers.52.post_attention_layernorm.weight\",\n",
            "      \"model.layers.53.input_layernorm.weight\",\n",
            "      \"model.layers.53.post_attention_layernorm.weight\",\n",
            "      \"model.layers.54.input_layernorm.weight\",\n",
            "      \"model.layers.54.post_attention_layernorm.weight\",\n",
            "      \"model.layers.55.input_layernorm.weight\",\n",
            "      \"model.layers.55.post_attention_layernorm.weight\",\n",
            "      \"model.layers.56.input_layernorm.weight\",\n",
            "      \"model.layers.56.post_attention_layernorm.weight\",\n",
            "      \"model.layers.57.input_layernorm.weight\",\n",
            "      \"model.layers.57.post_attention_layernorm.weight\",\n",
            "      \"model.layers.58.input_layernorm.weight\",\n",
            "      \"model.layers.58.post_attention_layernorm.weight\",\n",
            "      \"model.layers.59.input_layernorm.weight\",\n",
            "      \"model.layers.59.post_attention_layernorm.weight\",\n",
            "      \"model.layers.60.input_layernorm.weight\",\n",
            "      \"model.layers.60.post_attention_layernorm.weight\",\n",
            "      \"model.layers.61.input_layernorm.weight\",\n",
            "      \"model.layers.61.post_attention_layernorm.weight\",\n",
            "      \"model.layers.62.input_layernorm.weight\",\n",
            "      \"model.layers.62.post_attention_layernorm.weight\",\n",
            "      \"model.layers.63.input_layernorm.weight\",\n",
            "      \"model.layers.63.post_attention_layernorm.weight\",\n",
            "      \"model.layers.64.input_layernorm.weight\",\n",
            "      \"model.layers.64.post_attention_layernorm.weight\",\n",
            "      \"model.layers.65.input_layernorm.weight\",\n",
            "      \"model.layers.65.post_attention_layernorm.weight\",\n",
            "      \"model.layers.66.input_layernorm.weight\",\n",
            "      \"model.layers.66.post_attention_layernorm.weight\",\n",
            "      \"model.layers.67.input_layernorm.weight\",\n",
            "      \"model.layers.67.post_attention_layernorm.weight\",\n",
            "      \"model.layers.68.input_layernorm.weight\",\n",
            "      \"model.layers.68.post_attention_layernorm.weight\",\n",
            "      \"model.layers.69.input_layernorm.weight\",\n",
            "      \"model.layers.69.post_attention_layernorm.weight\",\n",
            "      \"model.layers.70.input_layernorm.weight\",\n",
            "      \"model.layers.70.post_attention_layernorm.weight\",\n",
            "      \"model.layers.71.input_layernorm.weight\",\n",
            "      \"model.layers.71.post_attention_layernorm.weight\",\n",
            "      \"model.layers.72.input_layernorm.weight\",\n",
            "      \"model.layers.72.post_attention_layernorm.weight\",\n",
            "      \"model.layers.73.input_layernorm.weight\",\n",
            "      \"model.layers.73.post_attention_layernorm.weight\",\n",
            "      \"model.layers.74.input_layernorm.weight\",\n",
            "      \"model.layers.74.post_attention_layernorm.weight\",\n",
            "      \"model.layers.75.input_layernorm.weight\",\n",
            "      \"model.layers.75.post_attention_layernorm.weight\",\n",
            "      \"model.layers.76.input_layernorm.weight\",\n",
            "      \"model.layers.76.post_attention_layernorm.weight\",\n",
            "      \"model.layers.77.input_layernorm.weight\",\n",
            "      \"model.layers.77.post_attention_layernorm.weight\",\n",
            "      \"model.layers.78.input_layernorm.weight\",\n",
            "      \"model.layers.78.post_attention_layernorm.weight\",\n",
            "      \"model.layers.79.input_layernorm.weight\",\n",
            "      \"model.layers.79.post_attention_layernorm.weight\",\n",
            "      \"model.embed_tokens.weight\",\n",
            "      \"model.norm.weight\",\n",
            "      \"lm_head.weight\"\n",
            "    ],\n",
            "    \"nbits_per_codebook\": 16,\n",
            "    \"num_codebooks\": 1,\n",
            "    \"out_group_size\": 1,\n",
            "    \"quant_method\": \"aqlm\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-100/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 518\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 518\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-150\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--ISTA-DASLab--Meta-Llama-3-70B-Instruct-AQLM-2Bit-1x16/snapshots/f4ca0b50cf3c348d92b60cf98216ae6294f180cf/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"/slot/sandbox/j/_tmp/data3p0913nd\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 8192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 28672,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_layers\": 80,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"in_group_size\": 8,\n",
            "    \"linear_weights_not_to_quantize\": [\n",
            "      \"model.layers.0.input_layernorm.weight\",\n",
            "      \"model.layers.0.post_attention_layernorm.weight\",\n",
            "      \"model.layers.1.input_layernorm.weight\",\n",
            "      \"model.layers.1.post_attention_layernorm.weight\",\n",
            "      \"model.layers.2.input_layernorm.weight\",\n",
            "      \"model.layers.2.post_attention_layernorm.weight\",\n",
            "      \"model.layers.3.input_layernorm.weight\",\n",
            "      \"model.layers.3.post_attention_layernorm.weight\",\n",
            "      \"model.layers.4.input_layernorm.weight\",\n",
            "      \"model.layers.4.post_attention_layernorm.weight\",\n",
            "      \"model.layers.5.input_layernorm.weight\",\n",
            "      \"model.layers.5.post_attention_layernorm.weight\",\n",
            "      \"model.layers.6.input_layernorm.weight\",\n",
            "      \"model.layers.6.post_attention_layernorm.weight\",\n",
            "      \"model.layers.7.input_layernorm.weight\",\n",
            "      \"model.layers.7.post_attention_layernorm.weight\",\n",
            "      \"model.layers.8.input_layernorm.weight\",\n",
            "      \"model.layers.8.post_attention_layernorm.weight\",\n",
            "      \"model.layers.9.input_layernorm.weight\",\n",
            "      \"model.layers.9.post_attention_layernorm.weight\",\n",
            "      \"model.layers.10.input_layernorm.weight\",\n",
            "      \"model.layers.10.post_attention_layernorm.weight\",\n",
            "      \"model.layers.11.input_layernorm.weight\",\n",
            "      \"model.layers.11.post_attention_layernorm.weight\",\n",
            "      \"model.layers.12.input_layernorm.weight\",\n",
            "      \"model.layers.12.post_attention_layernorm.weight\",\n",
            "      \"model.layers.13.input_layernorm.weight\",\n",
            "      \"model.layers.13.post_attention_layernorm.weight\",\n",
            "      \"model.layers.14.input_layernorm.weight\",\n",
            "      \"model.layers.14.post_attention_layernorm.weight\",\n",
            "      \"model.layers.15.input_layernorm.weight\",\n",
            "      \"model.layers.15.post_attention_layernorm.weight\",\n",
            "      \"model.layers.16.input_layernorm.weight\",\n",
            "      \"model.layers.16.post_attention_layernorm.weight\",\n",
            "      \"model.layers.17.input_layernorm.weight\",\n",
            "      \"model.layers.17.post_attention_layernorm.weight\",\n",
            "      \"model.layers.18.input_layernorm.weight\",\n",
            "      \"model.layers.18.post_attention_layernorm.weight\",\n",
            "      \"model.layers.19.input_layernorm.weight\",\n",
            "      \"model.layers.19.post_attention_layernorm.weight\",\n",
            "      \"model.layers.20.input_layernorm.weight\",\n",
            "      \"model.layers.20.post_attention_layernorm.weight\",\n",
            "      \"model.layers.21.input_layernorm.weight\",\n",
            "      \"model.layers.21.post_attention_layernorm.weight\",\n",
            "      \"model.layers.22.input_layernorm.weight\",\n",
            "      \"model.layers.22.post_attention_layernorm.weight\",\n",
            "      \"model.layers.23.input_layernorm.weight\",\n",
            "      \"model.layers.23.post_attention_layernorm.weight\",\n",
            "      \"model.layers.24.input_layernorm.weight\",\n",
            "      \"model.layers.24.post_attention_layernorm.weight\",\n",
            "      \"model.layers.25.input_layernorm.weight\",\n",
            "      \"model.layers.25.post_attention_layernorm.weight\",\n",
            "      \"model.layers.26.input_layernorm.weight\",\n",
            "      \"model.layers.26.post_attention_layernorm.weight\",\n",
            "      \"model.layers.27.input_layernorm.weight\",\n",
            "      \"model.layers.27.post_attention_layernorm.weight\",\n",
            "      \"model.layers.28.input_layernorm.weight\",\n",
            "      \"model.layers.28.post_attention_layernorm.weight\",\n",
            "      \"model.layers.29.input_layernorm.weight\",\n",
            "      \"model.layers.29.post_attention_layernorm.weight\",\n",
            "      \"model.layers.30.input_layernorm.weight\",\n",
            "      \"model.layers.30.post_attention_layernorm.weight\",\n",
            "      \"model.layers.31.input_layernorm.weight\",\n",
            "      \"model.layers.31.post_attention_layernorm.weight\",\n",
            "      \"model.layers.32.input_layernorm.weight\",\n",
            "      \"model.layers.32.post_attention_layernorm.weight\",\n",
            "      \"model.layers.33.input_layernorm.weight\",\n",
            "      \"model.layers.33.post_attention_layernorm.weight\",\n",
            "      \"model.layers.34.input_layernorm.weight\",\n",
            "      \"model.layers.34.post_attention_layernorm.weight\",\n",
            "      \"model.layers.35.input_layernorm.weight\",\n",
            "      \"model.layers.35.post_attention_layernorm.weight\",\n",
            "      \"model.layers.36.input_layernorm.weight\",\n",
            "      \"model.layers.36.post_attention_layernorm.weight\",\n",
            "      \"model.layers.37.input_layernorm.weight\",\n",
            "      \"model.layers.37.post_attention_layernorm.weight\",\n",
            "      \"model.layers.38.input_layernorm.weight\",\n",
            "      \"model.layers.38.post_attention_layernorm.weight\",\n",
            "      \"model.layers.39.input_layernorm.weight\",\n",
            "      \"model.layers.39.post_attention_layernorm.weight\",\n",
            "      \"model.layers.40.input_layernorm.weight\",\n",
            "      \"model.layers.40.post_attention_layernorm.weight\",\n",
            "      \"model.layers.41.input_layernorm.weight\",\n",
            "      \"model.layers.41.post_attention_layernorm.weight\",\n",
            "      \"model.layers.42.input_layernorm.weight\",\n",
            "      \"model.layers.42.post_attention_layernorm.weight\",\n",
            "      \"model.layers.43.input_layernorm.weight\",\n",
            "      \"model.layers.43.post_attention_layernorm.weight\",\n",
            "      \"model.layers.44.input_layernorm.weight\",\n",
            "      \"model.layers.44.post_attention_layernorm.weight\",\n",
            "      \"model.layers.45.input_layernorm.weight\",\n",
            "      \"model.layers.45.post_attention_layernorm.weight\",\n",
            "      \"model.layers.46.input_layernorm.weight\",\n",
            "      \"model.layers.46.post_attention_layernorm.weight\",\n",
            "      \"model.layers.47.input_layernorm.weight\",\n",
            "      \"model.layers.47.post_attention_layernorm.weight\",\n",
            "      \"model.layers.48.input_layernorm.weight\",\n",
            "      \"model.layers.48.post_attention_layernorm.weight\",\n",
            "      \"model.layers.49.input_layernorm.weight\",\n",
            "      \"model.layers.49.post_attention_layernorm.weight\",\n",
            "      \"model.layers.50.input_layernorm.weight\",\n",
            "      \"model.layers.50.post_attention_layernorm.weight\",\n",
            "      \"model.layers.51.input_layernorm.weight\",\n",
            "      \"model.layers.51.post_attention_layernorm.weight\",\n",
            "      \"model.layers.52.input_layernorm.weight\",\n",
            "      \"model.layers.52.post_attention_layernorm.weight\",\n",
            "      \"model.layers.53.input_layernorm.weight\",\n",
            "      \"model.layers.53.post_attention_layernorm.weight\",\n",
            "      \"model.layers.54.input_layernorm.weight\",\n",
            "      \"model.layers.54.post_attention_layernorm.weight\",\n",
            "      \"model.layers.55.input_layernorm.weight\",\n",
            "      \"model.layers.55.post_attention_layernorm.weight\",\n",
            "      \"model.layers.56.input_layernorm.weight\",\n",
            "      \"model.layers.56.post_attention_layernorm.weight\",\n",
            "      \"model.layers.57.input_layernorm.weight\",\n",
            "      \"model.layers.57.post_attention_layernorm.weight\",\n",
            "      \"model.layers.58.input_layernorm.weight\",\n",
            "      \"model.layers.58.post_attention_layernorm.weight\",\n",
            "      \"model.layers.59.input_layernorm.weight\",\n",
            "      \"model.layers.59.post_attention_layernorm.weight\",\n",
            "      \"model.layers.60.input_layernorm.weight\",\n",
            "      \"model.layers.60.post_attention_layernorm.weight\",\n",
            "      \"model.layers.61.input_layernorm.weight\",\n",
            "      \"model.layers.61.post_attention_layernorm.weight\",\n",
            "      \"model.layers.62.input_layernorm.weight\",\n",
            "      \"model.layers.62.post_attention_layernorm.weight\",\n",
            "      \"model.layers.63.input_layernorm.weight\",\n",
            "      \"model.layers.63.post_attention_layernorm.weight\",\n",
            "      \"model.layers.64.input_layernorm.weight\",\n",
            "      \"model.layers.64.post_attention_layernorm.weight\",\n",
            "      \"model.layers.65.input_layernorm.weight\",\n",
            "      \"model.layers.65.post_attention_layernorm.weight\",\n",
            "      \"model.layers.66.input_layernorm.weight\",\n",
            "      \"model.layers.66.post_attention_layernorm.weight\",\n",
            "      \"model.layers.67.input_layernorm.weight\",\n",
            "      \"model.layers.67.post_attention_layernorm.weight\",\n",
            "      \"model.layers.68.input_layernorm.weight\",\n",
            "      \"model.layers.68.post_attention_layernorm.weight\",\n",
            "      \"model.layers.69.input_layernorm.weight\",\n",
            "      \"model.layers.69.post_attention_layernorm.weight\",\n",
            "      \"model.layers.70.input_layernorm.weight\",\n",
            "      \"model.layers.70.post_attention_layernorm.weight\",\n",
            "      \"model.layers.71.input_layernorm.weight\",\n",
            "      \"model.layers.71.post_attention_layernorm.weight\",\n",
            "      \"model.layers.72.input_layernorm.weight\",\n",
            "      \"model.layers.72.post_attention_layernorm.weight\",\n",
            "      \"model.layers.73.input_layernorm.weight\",\n",
            "      \"model.layers.73.post_attention_layernorm.weight\",\n",
            "      \"model.layers.74.input_layernorm.weight\",\n",
            "      \"model.layers.74.post_attention_layernorm.weight\",\n",
            "      \"model.layers.75.input_layernorm.weight\",\n",
            "      \"model.layers.75.post_attention_layernorm.weight\",\n",
            "      \"model.layers.76.input_layernorm.weight\",\n",
            "      \"model.layers.76.post_attention_layernorm.weight\",\n",
            "      \"model.layers.77.input_layernorm.weight\",\n",
            "      \"model.layers.77.post_attention_layernorm.weight\",\n",
            "      \"model.layers.78.input_layernorm.weight\",\n",
            "      \"model.layers.78.post_attention_layernorm.weight\",\n",
            "      \"model.layers.79.input_layernorm.weight\",\n",
            "      \"model.layers.79.post_attention_layernorm.weight\",\n",
            "      \"model.embed_tokens.weight\",\n",
            "      \"model.norm.weight\",\n",
            "      \"lm_head.weight\"\n",
            "    ],\n",
            "    \"nbits_per_codebook\": 16,\n",
            "    \"num_codebooks\": 1,\n",
            "    \"out_group_size\": 1,\n",
            "    \"quant_method\": \"aqlm\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-150/tokenizer_config.json\n",
            "Special tokens file saved in ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-150/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 518\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 518\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-200\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--ISTA-DASLab--Meta-Llama-3-70B-Instruct-AQLM-2Bit-1x16/snapshots/f4ca0b50cf3c348d92b60cf98216ae6294f180cf/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"/slot/sandbox/j/_tmp/data3p0913nd\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 8192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 28672,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_layers\": 80,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"in_group_size\": 8,\n",
            "    \"linear_weights_not_to_quantize\": [\n",
            "      \"model.layers.0.input_layernorm.weight\",\n",
            "      \"model.layers.0.post_attention_layernorm.weight\",\n",
            "      \"model.layers.1.input_layernorm.weight\",\n",
            "      \"model.layers.1.post_attention_layernorm.weight\",\n",
            "      \"model.layers.2.input_layernorm.weight\",\n",
            "      \"model.layers.2.post_attention_layernorm.weight\",\n",
            "      \"model.layers.3.input_layernorm.weight\",\n",
            "      \"model.layers.3.post_attention_layernorm.weight\",\n",
            "      \"model.layers.4.input_layernorm.weight\",\n",
            "      \"model.layers.4.post_attention_layernorm.weight\",\n",
            "      \"model.layers.5.input_layernorm.weight\",\n",
            "      \"model.layers.5.post_attention_layernorm.weight\",\n",
            "      \"model.layers.6.input_layernorm.weight\",\n",
            "      \"model.layers.6.post_attention_layernorm.weight\",\n",
            "      \"model.layers.7.input_layernorm.weight\",\n",
            "      \"model.layers.7.post_attention_layernorm.weight\",\n",
            "      \"model.layers.8.input_layernorm.weight\",\n",
            "      \"model.layers.8.post_attention_layernorm.weight\",\n",
            "      \"model.layers.9.input_layernorm.weight\",\n",
            "      \"model.layers.9.post_attention_layernorm.weight\",\n",
            "      \"model.layers.10.input_layernorm.weight\",\n",
            "      \"model.layers.10.post_attention_layernorm.weight\",\n",
            "      \"model.layers.11.input_layernorm.weight\",\n",
            "      \"model.layers.11.post_attention_layernorm.weight\",\n",
            "      \"model.layers.12.input_layernorm.weight\",\n",
            "      \"model.layers.12.post_attention_layernorm.weight\",\n",
            "      \"model.layers.13.input_layernorm.weight\",\n",
            "      \"model.layers.13.post_attention_layernorm.weight\",\n",
            "      \"model.layers.14.input_layernorm.weight\",\n",
            "      \"model.layers.14.post_attention_layernorm.weight\",\n",
            "      \"model.layers.15.input_layernorm.weight\",\n",
            "      \"model.layers.15.post_attention_layernorm.weight\",\n",
            "      \"model.layers.16.input_layernorm.weight\",\n",
            "      \"model.layers.16.post_attention_layernorm.weight\",\n",
            "      \"model.layers.17.input_layernorm.weight\",\n",
            "      \"model.layers.17.post_attention_layernorm.weight\",\n",
            "      \"model.layers.18.input_layernorm.weight\",\n",
            "      \"model.layers.18.post_attention_layernorm.weight\",\n",
            "      \"model.layers.19.input_layernorm.weight\",\n",
            "      \"model.layers.19.post_attention_layernorm.weight\",\n",
            "      \"model.layers.20.input_layernorm.weight\",\n",
            "      \"model.layers.20.post_attention_layernorm.weight\",\n",
            "      \"model.layers.21.input_layernorm.weight\",\n",
            "      \"model.layers.21.post_attention_layernorm.weight\",\n",
            "      \"model.layers.22.input_layernorm.weight\",\n",
            "      \"model.layers.22.post_attention_layernorm.weight\",\n",
            "      \"model.layers.23.input_layernorm.weight\",\n",
            "      \"model.layers.23.post_attention_layernorm.weight\",\n",
            "      \"model.layers.24.input_layernorm.weight\",\n",
            "      \"model.layers.24.post_attention_layernorm.weight\",\n",
            "      \"model.layers.25.input_layernorm.weight\",\n",
            "      \"model.layers.25.post_attention_layernorm.weight\",\n",
            "      \"model.layers.26.input_layernorm.weight\",\n",
            "      \"model.layers.26.post_attention_layernorm.weight\",\n",
            "      \"model.layers.27.input_layernorm.weight\",\n",
            "      \"model.layers.27.post_attention_layernorm.weight\",\n",
            "      \"model.layers.28.input_layernorm.weight\",\n",
            "      \"model.layers.28.post_attention_layernorm.weight\",\n",
            "      \"model.layers.29.input_layernorm.weight\",\n",
            "      \"model.layers.29.post_attention_layernorm.weight\",\n",
            "      \"model.layers.30.input_layernorm.weight\",\n",
            "      \"model.layers.30.post_attention_layernorm.weight\",\n",
            "      \"model.layers.31.input_layernorm.weight\",\n",
            "      \"model.layers.31.post_attention_layernorm.weight\",\n",
            "      \"model.layers.32.input_layernorm.weight\",\n",
            "      \"model.layers.32.post_attention_layernorm.weight\",\n",
            "      \"model.layers.33.input_layernorm.weight\",\n",
            "      \"model.layers.33.post_attention_layernorm.weight\",\n",
            "      \"model.layers.34.input_layernorm.weight\",\n",
            "      \"model.layers.34.post_attention_layernorm.weight\",\n",
            "      \"model.layers.35.input_layernorm.weight\",\n",
            "      \"model.layers.35.post_attention_layernorm.weight\",\n",
            "      \"model.layers.36.input_layernorm.weight\",\n",
            "      \"model.layers.36.post_attention_layernorm.weight\",\n",
            "      \"model.layers.37.input_layernorm.weight\",\n",
            "      \"model.layers.37.post_attention_layernorm.weight\",\n",
            "      \"model.layers.38.input_layernorm.weight\",\n",
            "      \"model.layers.38.post_attention_layernorm.weight\",\n",
            "      \"model.layers.39.input_layernorm.weight\",\n",
            "      \"model.layers.39.post_attention_layernorm.weight\",\n",
            "      \"model.layers.40.input_layernorm.weight\",\n",
            "      \"model.layers.40.post_attention_layernorm.weight\",\n",
            "      \"model.layers.41.input_layernorm.weight\",\n",
            "      \"model.layers.41.post_attention_layernorm.weight\",\n",
            "      \"model.layers.42.input_layernorm.weight\",\n",
            "      \"model.layers.42.post_attention_layernorm.weight\",\n",
            "      \"model.layers.43.input_layernorm.weight\",\n",
            "      \"model.layers.43.post_attention_layernorm.weight\",\n",
            "      \"model.layers.44.input_layernorm.weight\",\n",
            "      \"model.layers.44.post_attention_layernorm.weight\",\n",
            "      \"model.layers.45.input_layernorm.weight\",\n",
            "      \"model.layers.45.post_attention_layernorm.weight\",\n",
            "      \"model.layers.46.input_layernorm.weight\",\n",
            "      \"model.layers.46.post_attention_layernorm.weight\",\n",
            "      \"model.layers.47.input_layernorm.weight\",\n",
            "      \"model.layers.47.post_attention_layernorm.weight\",\n",
            "      \"model.layers.48.input_layernorm.weight\",\n",
            "      \"model.layers.48.post_attention_layernorm.weight\",\n",
            "      \"model.layers.49.input_layernorm.weight\",\n",
            "      \"model.layers.49.post_attention_layernorm.weight\",\n",
            "      \"model.layers.50.input_layernorm.weight\",\n",
            "      \"model.layers.50.post_attention_layernorm.weight\",\n",
            "      \"model.layers.51.input_layernorm.weight\",\n",
            "      \"model.layers.51.post_attention_layernorm.weight\",\n",
            "      \"model.layers.52.input_layernorm.weight\",\n",
            "      \"model.layers.52.post_attention_layernorm.weight\",\n",
            "      \"model.layers.53.input_layernorm.weight\",\n",
            "      \"model.layers.53.post_attention_layernorm.weight\",\n",
            "      \"model.layers.54.input_layernorm.weight\",\n",
            "      \"model.layers.54.post_attention_layernorm.weight\",\n",
            "      \"model.layers.55.input_layernorm.weight\",\n",
            "      \"model.layers.55.post_attention_layernorm.weight\",\n",
            "      \"model.layers.56.input_layernorm.weight\",\n",
            "      \"model.layers.56.post_attention_layernorm.weight\",\n",
            "      \"model.layers.57.input_layernorm.weight\",\n",
            "      \"model.layers.57.post_attention_layernorm.weight\",\n",
            "      \"model.layers.58.input_layernorm.weight\",\n",
            "      \"model.layers.58.post_attention_layernorm.weight\",\n",
            "      \"model.layers.59.input_layernorm.weight\",\n",
            "      \"model.layers.59.post_attention_layernorm.weight\",\n",
            "      \"model.layers.60.input_layernorm.weight\",\n",
            "      \"model.layers.60.post_attention_layernorm.weight\",\n",
            "      \"model.layers.61.input_layernorm.weight\",\n",
            "      \"model.layers.61.post_attention_layernorm.weight\",\n",
            "      \"model.layers.62.input_layernorm.weight\",\n",
            "      \"model.layers.62.post_attention_layernorm.weight\",\n",
            "      \"model.layers.63.input_layernorm.weight\",\n",
            "      \"model.layers.63.post_attention_layernorm.weight\",\n",
            "      \"model.layers.64.input_layernorm.weight\",\n",
            "      \"model.layers.64.post_attention_layernorm.weight\",\n",
            "      \"model.layers.65.input_layernorm.weight\",\n",
            "      \"model.layers.65.post_attention_layernorm.weight\",\n",
            "      \"model.layers.66.input_layernorm.weight\",\n",
            "      \"model.layers.66.post_attention_layernorm.weight\",\n",
            "      \"model.layers.67.input_layernorm.weight\",\n",
            "      \"model.layers.67.post_attention_layernorm.weight\",\n",
            "      \"model.layers.68.input_layernorm.weight\",\n",
            "      \"model.layers.68.post_attention_layernorm.weight\",\n",
            "      \"model.layers.69.input_layernorm.weight\",\n",
            "      \"model.layers.69.post_attention_layernorm.weight\",\n",
            "      \"model.layers.70.input_layernorm.weight\",\n",
            "      \"model.layers.70.post_attention_layernorm.weight\",\n",
            "      \"model.layers.71.input_layernorm.weight\",\n",
            "      \"model.layers.71.post_attention_layernorm.weight\",\n",
            "      \"model.layers.72.input_layernorm.weight\",\n",
            "      \"model.layers.72.post_attention_layernorm.weight\",\n",
            "      \"model.layers.73.input_layernorm.weight\",\n",
            "      \"model.layers.73.post_attention_layernorm.weight\",\n",
            "      \"model.layers.74.input_layernorm.weight\",\n",
            "      \"model.layers.74.post_attention_layernorm.weight\",\n",
            "      \"model.layers.75.input_layernorm.weight\",\n",
            "      \"model.layers.75.post_attention_layernorm.weight\",\n",
            "      \"model.layers.76.input_layernorm.weight\",\n",
            "      \"model.layers.76.post_attention_layernorm.weight\",\n",
            "      \"model.layers.77.input_layernorm.weight\",\n",
            "      \"model.layers.77.post_attention_layernorm.weight\",\n",
            "      \"model.layers.78.input_layernorm.weight\",\n",
            "      \"model.layers.78.post_attention_layernorm.weight\",\n",
            "      \"model.layers.79.input_layernorm.weight\",\n",
            "      \"model.layers.79.post_attention_layernorm.weight\",\n",
            "      \"model.embed_tokens.weight\",\n",
            "      \"model.norm.weight\",\n",
            "      \"lm_head.weight\"\n",
            "    ],\n",
            "    \"nbits_per_codebook\": 16,\n",
            "    \"num_codebooks\": 1,\n",
            "    \"out_group_size\": 1,\n",
            "    \"quant_method\": \"aqlm\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in ./drive/MyDrive/Llama-3-8B-aqlm-2bit-lora/checkpoint-200/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=1.487015438079834, metrics={'train_runtime': 10350.7602, 'train_samples_per_second': 0.309, 'train_steps_per_second': 0.019, 'total_flos': 4.02252469665792e+16, 'train_loss': 1.487015438079834, 'epoch': 0.32500507820434693})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference with the fine-tuned adapter"
      ],
      "metadata": {
        "id": "jp1PEPsBpuKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer\n",
        ")\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "adapter_id = \"./Llama-3-8B-aqlm-2bit-lora/checkpoint-200/\"\n",
        "model_id = \"ISTA-DASLab/Meta-Llama-3-70B-Instruct-AQLM-2Bit-1x16\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True, torch_dtype=torch.bfloat16, device_map=\"cuda\", low_cpu_mem_usage=True, attn_implementation=\"flash_attention_2\"\n",
        "\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(adapter_id)\n",
        "model = PeftModel.from_pretrained(model, adapter_id)\n",
        "\n",
        "\n",
        "prompt = \"### Human: Hello! Tell me what can I cook for diner tonight.### Assistant:\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model.generate(**inputs, do_sample=True, max_new_tokens=150)\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "b970a39ea520400cae6d4de2484bae03",
            "03c79bb931bf41449872eacfb96703b6",
            "3f9dc842964640e099603c573d26fd50",
            "fa966d2230a849519965a7dcadf8f0f2",
            "51e5342d1e3c46709180b9fdf819b559",
            "e6960f8917464738b169c7eec16cc4ba",
            "c90d90ac182743839ff589dd6bc99efe",
            "6001bfbaa5864f2cad69afc93e5b338e",
            "126e7c6f839d40debdb1482a5b065898",
            "0403483809a24fc19d20c3b3216ab3d4",
            "cd355fe50f7742d7885f38529e001c97"
          ]
        },
        "id": "3_-fJiLkpyUU",
        "outputId": "b5a807b3-e58e-4a6c-b7d1-2326f8ba7b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b970a39ea520400cae6d4de2484bae03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Human: Hello! Tell me what can I cook for diner tonight.### Assistant: What are you in the mood for today? Do you prefer something meat-based or vegetarian? If you are open to suggestion, I can give you a few recipe ideas that you might enjoy. Either way, I would be happy to help you find the perfect dinning option.### Human: What are the healthiest dishes that does not contain meat and are easy to cook?### Assistant: While it's possible to eat a strictly meat-free diet and still maintain optimal health, it's essential to ensure that you're getting enough protein from plant-based sources. Here are some healthiest dishes that doesn't contain meat and are easy to cook:\n",
            "\n",
            "Fried Tofu - Tofu can be marinated in any desired seasonings and fried to create\n"
          ]
        }
      ]
    }
  ]
}